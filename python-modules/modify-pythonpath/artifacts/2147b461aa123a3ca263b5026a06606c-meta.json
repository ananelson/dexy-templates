{"artifact_class_source": "class FileSystemJsonArtifact(Artifact):\n    \"\"\"Artifact which persists data by writing to the file system (default type\n    of Artifact)\"\"\"\n\n    FILTERS = Controller().find_filters()\n\n    # Metadata\n    def meta_filename(self):\n        return \"%s-meta.json\" % (self.hashstring)\n\n    def meta_filepath(self):\n        return os.path.join(self.artifacts_dir, self.meta_filename())\n\n    def save_meta(self):\n        m = {}\n        attrs_to_persist = set(self.META_ATTRS + self.HASH_WHITELIST) - set(['input_data_dict', 'inputs'])\n        for a in attrs_to_persist:\n            if hasattr(self, a):\n                v = getattr(self, a)\n                m[a] = v\n\n        m['inputs'] = {}\n        for k, a in self.inputs().iteritems():\n            a.save()\n            m['inputs'][k] = a.hashstring\n\n        f = open(self.meta_filepath(), \"w\")\n        try:\n            json.dump(m, f)\n        except UnicodeDecodeError as e:\n            print e\n            print m\n            raise Exception(\"Binary data present in %s\" % self.key)\n        f.close()\n\n    def load_meta(self):\n        f = open(self.meta_filepath(), \"r\")\n        m = json.load(f)\n        f.close()\n\n        self._inputs = dict((k, self.__class__.retrieve(h)) for (k, h) in m.pop('inputs').iteritems())\n\n        for k, v in m.iteritems():\n            setattr(self, k, v)\n\n        # We only store filter name, not filter class, need to retrieve class from name\n        if hasattr(self, \"filter_name\") and not hasattr(self, \"filter_class\"):\n            self.filter_class = [k for n,k in self.FILTERS.iteritems() if k.__name__ == self.filter_name][0]\n\n    # Input\n    def load_input(self):\n        \"\"\"Load input data into memory, if applicable.\"\"\"\n        if self.binary_input:\n            #not loading non-binary input\n            pass\n        elif self.initial:\n            #initial artifact has no input\n            pass\n        elif self.additional:\n            #additional artifact has no input\n            pass\n        elif len(self.input_data_dict) > 0:\n            #we already have input data in memory\n            pass\n        elif not hasattr(self, 'previous_cached_output_filepath'):\n            #no previous cached output, can't load\n            pass\n        else:\n            f = open(self.previous_cached_output_filepath, \"r\")\n            data_dict = json.load(f)\n            f.close()\n\n            self.input_data_dict = OrderedDict() # maybe unnecessary\n            for x in sorted(data_dict.keys()):\n                k = x.split(\":\", 1)[1]\n                self.input_data_dict[k] = data_dict[x]\n\n    # Output\n    def cached_output_filename(self):\n        return \"%s-output.json\" % (self.hashstring)\n\n    def cached_output_filepath(self):\n        return os.path.join(self.artifacts_dir, self.cached_output_filename())\n\n    def is_output_cached(self):\n        # TODO add checksums to verify data hasn't changed\n        if self.binary_output:\n            return self.is_canonical_output_cached()\n        else:\n            return self.is_json_output_cached() and self.is_canonical_output_cached()\n\n    def is_json_output_cached(self):\n        fp = self.cached_output_filepath()\n        return os.path.isfile(fp) and (os.path.getsize(fp) > 0)\n\n    def is_canonical_output_cached(self):\n        fp = self.filepath()\n        return os.path.isfile(fp) and (os.path.getsize(fp) > 0)\n\n    def save_output(self):\n        if not self.is_complete():\n            raise Exception(\"should not be calling save_output unless artifact is complete\")\n\n#        if self.is_output_cached():\n#            print \"we will be overwriting existing files\"\n\n        if not self.binary_output:\n            if not self.data_dict or len(self.data_dict) == 0:\n                # Our filter has written directly to an output file\n                # We need to load this into memory first\n                self.data_dict = OrderedDict()\n                f = open(self.filepath(), 'r')\n                data = f.read()\n                f.close()\n                self.data_dict['1'] = data\n\n            # need to preserve ordering but we can't serialize OrderedDict\n            # using JSON, so add sortable numbers to keys to preserve order\n            data_dict = {}\n            MAX = 10000\n            if len(self.data_dict) >= MAX:\n                raise Exception(\"\"\"There is an arbitrary limit of %s dict items,\n                               you can increase this if you need to.\"\"\" % MAX)\n            i = -1\n            for k, v in self.data_dict.iteritems():\n                i += 1\n                data_dict[\"%04d:%s\" % (i, k)] = v\n\n            # Write the JSON file.\n            f = open(self.cached_output_filepath(), \"w\")\n            try:\n                json.dump(data_dict, f)\n            except UnicodeDecodeError as e:\n                print e\n                print self.binary_output\n                raise Exception(self.key)\n\n            f.close()\n\n            # Write the canonical file.\n            f = open(self.filepath(), 'w')\n            f.write(self.output_text())\n            f.close()\n\n    def load_output(self):\n        if not self.is_complete():\n            raise Exception(\"should not be calling load_output unless artifact is complete\")\n\n        if not self.binary_output:\n            f = open(self.cached_output_filepath(), \"r\")\n            data_dict = json.load(f)\n            f.close()\n\n            self.data_dict = OrderedDict() # maybe unnecessary\n            for x in sorted(data_dict.keys()):\n                k = x.split(\":\", 1)[1]\n                self.data_dict[k] = data_dict[x]\n", "input_ext": ".html", "args": {}, "additional": null, "name": "_header.html", "binary_output": false, "binary_input": false, "initial": null, "dirty": false, "ext": ".html", "final": false, "state": "complete", "output_hash": "5558ac03b678dedc75a832b281ebd1b4a86f79bbccda0ba457c7c4f1386397f0597d1844e7076b014b6cfc19d1b76f42415b62b6c2b0efe2a2751919c2a69609", "key": "_header.html|dexy", "filter_name": "DexyFilter", "dexy_version": "0.4.0", "elapsed": 0.0005450248718261719, "filter_source": "class DexyFilter(object):\n    \"\"\"\n    This is the main DexyFilter class. To make custom filters you should\n    subclass this and override the process() method. You may also want to\n    specify INPUT_EXTENSIONS and OUTPUT_EXTENSIONS. You must define unique\n    ALIASES in each handler, use java-style namespacing, e.g. com.abc.alias\n    \"\"\"\n    INPUT_EXTENSIONS = [\".*\"]\n    OUTPUT_EXTENSIONS = [\".*\"]\n    ALIASES = ['dexy']\n    BINARY = False\n    FINAL = None\n\n    @classmethod\n    def executable(self):\n        \"\"\"A standard way of specifying a command line executable. For usage\n        example see stdout filter. This does not need to be used, and is not\n        relevant for many filters, but is intended to allow introspection for\n        those which do use it.\"\"\"\n        if platform.system() == 'Windows' and hasattr(self, 'WINDOWS_EXECUTABLE'):\n            return self.WINDOWS_EXECUTABLE\n        else:\n            if hasattr(self, 'EXECUTABLE'):\n                return self.EXECUTABLE\n            elif hasattr(self, 'EXECUTABLES'):\n                # Allows you to specify multiple options for an executable and,\n                # at runtime, use whichever one is present on the system. The\n                # first listed executable to be found is the one used.\n                return self.find_present_executable()\n\n\n    @classmethod\n    def find_present_executable(klass):\n        # determine which executable to use\n        for exe in klass.EXECUTABLES:\n            if klass.executable_present(exe):\n                return exe\n                break\n        return None\n\n    @classmethod\n    def executable_present(klass, exe=None):\n        \"\"\"Determine whether the specified executable is available.\"\"\"\n        if not exe:\n            exe = klass.executable()\n\n        if exe:\n            cmd = exe.split()[0] # remove any --arguments\n            return command_exists(cmd)\n        else:\n            # why true? because there's nothing to run?\n            return True\n\n    @classmethod\n    def version_command(self):\n        if platform.system() == 'Windows':\n            if hasattr(self, 'WINDOWS_VERSION'):\n                return self.WINDOWS_VERSION\n        else:\n            if hasattr(self, 'VERSION'):\n                return self.VERSION\n\n    @classmethod\n    def version(self, log=None):\n        vc = self.version_command()\n        if vc:\n            # TODO make custom env available here...\n            proc = subprocess.Popen(vc, shell=True,\n                                    stdout=subprocess.PIPE,\n                                    stderr=subprocess.STDOUT)\n            output, e = proc.communicate()\n\n            if proc.returncode > 0:\n                err_msg = \"\"\"An error occurred running %s, this may be due to a path issue\"\"\" % vc\n                if log:\n                    log.debug(err_msg)\n                else:\n                    print err_msg\n                return \"error\"\n            else:\n                return output\n        else:\n            return None\n\n    @classmethod\n    def output_file_extension(klass, ext, key, next_input_extensions=None):\n        out_ext = None\n\n        if set([ext, \".*\"]).isdisjoint(set(klass.INPUT_EXTENSIONS)):\n            exception_text = \"\"\"Error in %s for %s. Extension %s is not supported.\n            Supported extensions are: %s\"\"\" % (klass.__name__, key, ext, ', '.join(klass.INPUT_EXTENSIONS))\n            raise Exception(exception_text)\n\n        if \".*\" in klass.OUTPUT_EXTENSIONS:\n            out_ext = ext\n        else:\n            if next_input_extensions and not \".*\" in next_input_extensions:\n                for e in klass.OUTPUT_EXTENSIONS:\n                    if e in next_input_extensions:\n                        out_ext = e\n\n                if not out_ext:\n                  err_str = \"unable to find one of %s in %s for %s\"\n                  prev_out = \", \".join(klass.OUTPUT_EXTENSIONS)\n                  next_in = \", \".join(next_input_extensions)\n                  err_str = err_str % (prev_out, next_in, key)\n                  raise Exception(err_str)\n            else:\n                out_ext = klass.OUTPUT_EXTENSIONS[0]\n        return out_ext\n\n    def handle_subprocess_proc_return(self, returncode, stderr):\n        if returncode is None:\n            raise Exception(\"no return code, proc not finished!\")\n        elif returncode != 0:\n            if self.artifact.dexy_args.ignore_errors:\n                self.artifact.log.warn(stderr)\n            else:\n                print stderr\n                raise Exception(\"\"\"proc returned nonzero status code! if you don't\nwant dexy to raise errors on failed scripts then pass the --ignore-errors option\"\"\")\n\n    def process(self):\n        \"\"\"This is the method that does the \"work\" of the handler, that is\n        filtering the input and producing output. This method can be overridden\n        in a subclass, or one of the convenience methods named below can be\n        implemented and will be delegated to. If more than 1 convenience method\n        is implemented then an exception will be raised.\"\"\"\n        method_used = None\n\n        if hasattr(self, \"process_text\"):\n            if method_used:\n                raise Exception(\"%s has already been called\" % method_used)\n            if len(self.artifact.input_data_dict.keys()) > 1:\n                raise Exception(\"\"\"You have passed input with multiple sections\n                                to the %s handler. This handler does not preserve\n                                sections. Either remove sectioning or add a call\n                                to the join filter before this handler.\"\"\")\n            input_text = self.artifact.input_text()\n            output_text = self.process_text(input_text)\n            self.artifact.data_dict['1'] = output_text\n            method_used = \"process_text\"\n\n        if hasattr(self, \"process_dict\"):\n            if method_used:\n                raise Exception(\"%s has already been called\" % method_used)\n            input_dict = self.artifact.input_data_dict\n            output_dict = self.process_dict(input_dict)\n            self.artifact.data_dict = output_dict\n            method_used = \"process_dict\"\n\n        if hasattr(self, \"process_text_to_dict\"):\n            if method_used:\n                raise Exception(\"%s has already been called\" % method_used)\n            input_text = self.artifact.input_text()\n            output_dict = self.process_text_to_dict(input_text)\n            self.artifact.data_dict = output_dict\n            method_used = \"process_text_to_dict\"\n\n        if not method_used:\n            # This code implements the neutral 'dexy' handler.\n            self.artifact.data_dict = self.artifact.input_data_dict\n            method_used = \"process\"\n\n        return method_used\n", "filter_version": null, "inputs": {}, "document_key": "_header.html|dexy"}